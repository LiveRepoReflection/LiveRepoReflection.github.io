<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tuning the Tide: Repository-based Code Reflection</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css">
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            padding-top: 20px;
        }
        .paper-icon {
            max-width: 100px;
            margin-bottom: 20px;
        }
        .abstract {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 5px;
            margin-bottom: 30px;
        }
        .navbar {
            margin-bottom: 30px;
        }
        .feature-box {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 20px;
            margin-bottom: 20px;
            transition: transform 0.3s;
        }
        .feature-box:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        }
        .authors {
            font-style: italic;
            margin-bottom: 20px;
        }
        .footer {
            margin-top: 50px;
            padding: 20px 0;
            background-color: #f8f9fa;
        }
        .figure-container {
            margin-bottom: 30px;
        }
        .figure-container img {
            max-width: 100%;
            border: 1px solid #ddd;
            border-radius: 5px;
        }
    </style>
</head>
<body>
    <nav class="navbar navbar-expand-lg navbar-light bg-light">
        <div class="container">
            <a class="navbar-brand" href="home.html">LiveRepoReflection</a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item">
                        <a class="nav-link active" href="home.html">Home</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="index.html">Leaderboard</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <div class="container">
        <div class="row mb-5">
            <div class="col-md-8 offset-md-2 text-center">
                <div class="d-flex align-items-center justify-content-center gap-3 mb-4">
                    <img src="assets/figure0.png" alt="Paper Icon" class="paper-icon" width="50" style="padding-top: 0px;">
                    <h4 class="mb-4" style="padding-top: 0px; margin-bottom: 0px;">
                        Turning the Tide: Repository-based Code Reflection
                    </h4>                
                </div>
                <div class="authors">
                    Wei Zhang, Jian Yang, Jiaxi Yang, Ya Wang, Zhoujun Li, Zeyu Cui, Binyuan Hui, Junyang Lin
                </div>
                <div class="d-flex justify-content-center gap-1 mb-0">
                    <a href="https://LiveRepoReflection.github.io/home.html" class="btn btn-outline-secondary">üè† Project Page</a>
                    <a href="https://LiveRepoReflection.github.io/index.html" class="btn btn-outline-secondary">üèÜ Leaderboard</a>
                    <a href="https://github.com/LiveRepoReflection/LiveRepoReflection-Project" class="btn btn-outline-secondary">üê≥ GitHub</a>
                    <a href="https://github.com/LiveRepoReflection/LiveRepoReflection" class="btn btn-outline-secondary">üìä Benchmark Dataset</a>
                    <a href="https://arxiv.org/abs/2507.09866" class="btn btn-outline-secondary">üìÑ Paper</a>
                </div>
            </div>
        </div>
        
        <div class="row">
            <div class="col-lg-10 offset-lg-1">
                <div class="abstract">
                    <h3>Abstract</h3>
                    <p>
                        Code large language models (LLMs) enhance programming by understanding and generating code across languages, offering intelligent feedback, bug detection, and code updates through reflection, improving development efficiency and accessibility. While benchmarks (e.g. HumanEval/LiveCodeBench) evaluate code generation and real-world relevance, previous works ignore the scenario of modifying code in repositories. Considering challenges remaining in improving reflection capabilities and avoiding data contamination in dynamic benchmarks, we introduce LiveRepoReflection, a challenging benchmark for evaluating code understanding and generation in multi-file repository contexts, featuring 1,888 rigorously filtered test cases across 6 programming languages to ensure diversity, correctness, and high difficulty. Further, we create RepoReflection-Instruct, a large-scale, quality-filtered instruction-tuning dataset derived from diverse sources, used to train RepoReflectionCoder through a two-turn dialogue process involving code generation and error-driven repair. The leaderboard evaluates over 40 LLMs to reflect the model performance of repository-based code reflection.
                    </p>
                </div>

                <h2>Overview</h2>
                <p>
                    Code large language models (LLMs) represent a significant advancement in comprehending and producing code across numerous programming languages. Fueled by extensive training on massive code repositories, LLMs empower developers by offering intelligent feedback, identifying potential bugs, and updating code snippets from human instructions. Code reflection refers to the ability of LLMs to examine and modify their previous responses. Using reflection, LLMs can streamline the development process, boost efficiency, and make programming more accessible to a wider number of developers.
                </p>

                <div class="figure-container text-center">
                    <img src="assets/figure1.png" alt="Comparison between general code generation tasks and LiveRepoReflection tasks." width="50%">
                    <p class="mt-2"><strong></strong> Comparison between general code generation tasks and LiveRepoReflection tasks.</p>
                </div>

                <div class="row mt-5 mb-4">
                    <div class="col-md-6">
                        <div class="feature-box">
                            <h3>LiveRepoReflection Benchmark</h3>
                            <p>
                                A challenging benchmark for evaluating code understanding and generation in multi-file repository contexts, featuring 1,888 rigorously filtered test cases across 6 programming languages (Python, Java, C++, Rust, Go, JavaScript) to ensure diversity, correctness, and high difficulty.
                            </p>
                        </div>
                    </div>
                    <div class="col-md-6">
                        <div class="feature-box">
                            <h3>RepoReflection-Instruct Dataset</h3>
                            <p>
                                A large-scale, quality-filtered instruction-tuning dataset derived from diverse sources including newly automatically generated examples. The dataset was created using sophisticated quality filtering mechanisms and decontamination techniques.
                            </p>
                        </div>
                    </div>
                </div>

                <div class="row mb-5">
                    <div class="col-md-6">
                        <div class="feature-box">
                            <h3>RepoReflectionCoder Model</h3>
                            <p>
                                A specialized LLM trained on the RepoReflection-Instruct dataset through a two-turn dialogue process involving code generation and error-driven repair, with enhanced capabilities for repository-based code reflection.
                            </p>
                        </div>
                    </div>
                    <div class="col-md-6">
                        <div class="feature-box">
                            <h3>Comprehensive Evaluation</h3>
                            <p>
                                Systematic evaluation of over 40 LLMs on the LiveRepoReflection benchmark, creating a dynamic leaderboard to track model performance and measuring alignment between model-generated responses and human preferences.
                            </p>
                        </div>
                    </div>
                </div>

                <h2>Key Contributions</h2>
                <ul class="list-group mb-5">
                    <li class="list-group-item">
                        <strong>High-Quality Benchmark</strong>: We propose a high-quality, high-difficulty benchmark for evaluating code reflection of LLMs, featuring 1,888 rigorously filtered test cases across 6 programming languages. The benchmark emphasizes diversity, correctness, and challenge by retaining only cases that stump strong LLMs and undergo human annotation.
                    </li>
                    <li class="list-group-item">
                        <strong>Structured Dataset Creation</strong>: Starting with 500k examples, a strict rejection sampling process ensured high quality by filtering repositories based on criteria such as having unit-test files, reference answer files, aligned code signatures and answers, compatible environment configurations, and standardized file names.
                    </li>
                    <li class="list-group-item">
                        <strong>Systematic Evaluation</strong>: Our systematic evaluation of over 40+ LLMs on LiveRepoReflection led to the creation of a dynamic leaderboard to track model performance, with extensive experiments demonstrating that LiveRepoReflection effectively measures the alignment between model-generated responses and human preferences.
                    </li>
                </ul>

                <div class="figure-container text-center">
                    <img src="assets/figure3.png" alt="Figure 3: Comparison of dataset scales and structures between Aider Polyglot Benchmark and LiveRepoReflection." width="50%">
                    <p class="mt-2"><strong></strong> Comparison of dataset scales and structures between Aider Polyglot Benchmark and LiveRepoReflection.</p>
                </div>

                <h2>Pipeline Overview</h2>
                <p>
                    The paper introduces an automatic creation pipeline to dynamically update the large-scale instruction corpus and evaluation benchmark to avoid data hacking:
                </p>
                <ol>
                    <li>
                        <strong>Repository structure design</strong>: Standardized repository code data file structure designed to be streamlined while ensuring normal evaluation.
                    </li>
                    <li>
                        <strong>Seed code data collection</strong>: High-quality, diverse code samples collected from multiple public sources like GitHub, Hugging Face, and Reddit.
                    </li>
                    <li>
                        <strong>Multiple-turn dialogue data generation</strong>: Using a mix of "creative" and "reasoning" LLMs to generate program topics, definitions, unit tests, and reference answers.
                    </li>
                    <li>
                        <strong>Cross-execution verification</strong>: Rigorous testing and validation to ensure correctness and appropriate difficulty.
                    </li>
                    <li>
                        <strong>Human annotation</strong>: Final validation and refinement by trained annotators to ensure quality.
                    </li>
                </ol>

                <div class="figure-container text-center">
                    <img src="assets/figure2.png" alt="Overview of Construction Pipeline." width="100%">
                    <p class="mt-2"><strong></strong> Overview of Construction Pipeline.</p>
                </div>

                <h2>Evaluation Edit Format</h2>
                <div class="figure-container text-center">
                    <img src="assets/figure4.png" alt="Two evaluation edit format of LiveRepoReflection." width="40%">
                    <p class="mt-2"><strong></strong> Two evaluation edit format of LiveRepoReflection.</p>
                </div>

                <h2>Comparison with Aider Polyglot</h2>
                <div class="figure-container text-center">
                    <img src="assets/figure5.png" alt="Performance comparison between LiveRepoReflection and the Aider Polyglot Benchmark." width="100%">
                    <p class="mt-2"><strong></strong> Performance comparison between LiveRepoReflection and the Aider Polyglot Benchmark.</p>
                </div>

                <h2>Pass@k Analysis</h2>
                <div class="figure-container text-center">
                    <img src="assets/figure6.png" alt="Pass@k (k=1‚Äì10) curves for nine LLMs." width="100%">
                    <p class="mt-2"><strong></strong> Pass@k (k=1‚Äì10) curves for nine LLMs.</p>
                </div>

                <h2>File Structure</h2>
                <div class="figure-container text-center">
                    <img src="assets/figure7.png" alt="Polyglot repository code file structure examples." width="100%">
                    <p class="mt-2"><strong></strong> Polyglot repository code file structure examples.</p>
                </div>

                <div class="text-center mt-5 mb-5">
                    <a href="index.html" class="btn btn-lg btn-primary">View Leaderboard Results</a>
                </div>
            </div>
        </div>
    </div>

    <footer class="footer">
        <div class="container">
            <div class="text-center">
                <p>Tuning the Tide: Repository-based Code Reflection</p>
                <p><a href="https://LiveRepoReflection.github.io">https://LiveRepoReflection.github.io</a></p>
            </div>
        </div>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>
